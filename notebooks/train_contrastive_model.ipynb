{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "!git clone -b <midi-tokenization> --single-branch https://github.com/imabeastdrew/Martydepth.git\n",
        "%cd Martydepth\n",
        "\n",
        "# Install the package in development mode\n",
        "%pip install -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from pathlib import Path\n",
        "import wandb\n",
        "import yaml\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add project root to Python path\n",
        "import sys\n",
        "sys.path.append('.')\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "# Import project modules\n",
        "from src.data.dataset import create_dataloader\n",
        "from src.models.contrastive_reward_model import ContrastiveRewardModel\n",
        "from src.training.train_reward_model import InfoNCELoss\n",
        "from src.config.tokenization_config import PAD_TOKEN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load configuration\n",
        "print(os.getcwd())\n",
        "config_path = 'src/training/configs/contrastive_reward_base.yaml'\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Initialize wandb\n",
        "run_name = f\"contrastive_L{config['num_layers']}_H{config['num_heads']}_D{config['embed_dim']}_seq{config['max_seq_length']}_bs{config['batch_size']}_lr{config['learning_rate']}\"\n",
        "\n",
        "wandb.init(\n",
        "    project=config['wandb_project'],\n",
        "    name=run_name,\n",
        "    config=config,\n",
        "    job_type=\"contrastive_training\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataloaders\n",
        "train_loader, tokenizer_info = create_dataloader(\n",
        "    data_dir=Path(config['data_dir']),\n",
        "    split=\"train\",\n",
        "    batch_size=config['batch_size'],\n",
        "    num_workers=config['num_workers'],\n",
        "    sequence_length=config['max_seq_length'],\n",
        "    mode='contrastive',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader, _ = create_dataloader(\n",
        "    data_dir=Path(config['data_dir']),\n",
        "    split=\"valid\",\n",
        "    batch_size=config['batch_size'],\n",
        "    num_workers=config['num_workers'],\n",
        "    sequence_length=config['max_seq_length'],\n",
        "    mode='contrastive',\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize model, loss function, and optimizer\n",
        "model = ContrastiveRewardModel(\n",
        "    melody_vocab_size=tokenizer_info['melody_vocab_size'],\n",
        "    chord_vocab_size=tokenizer_info['chord_vocab_size'],\n",
        "    embed_dim=config['embed_dim'],\n",
        "    num_heads=config['num_heads'],\n",
        "    num_layers=config['num_layers'],\n",
        "    dropout=config['dropout'],\n",
        "    max_seq_length=config['max_seq_length'],\n",
        "    pad_token_id=PAD_TOKEN\n",
        ").to(device)\n",
        "\n",
        "print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters.\")\n",
        "\n",
        "# Initialize loss function with temperature from config\n",
        "loss_fn = InfoNCELoss(temperature=config['temperature'])\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = Adam(model.parameters(), lr=config['learning_rate'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, train_loader, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc='Training')\n",
        "    for batch in pbar:\n",
        "        # Move batch to device\n",
        "        melody_tokens = batch['melody_tokens'].to(device)\n",
        "        chord_tokens = batch['chord_tokens'].to(device)\n",
        "        \n",
        "        # Create padding masks\n",
        "        melody_mask = (melody_tokens == model.pad_token_id)\n",
        "        chord_mask = (chord_tokens == model.pad_token_id)\n",
        "        \n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        melody_embeds, chord_embeds = model(\n",
        "            melody_tokens=melody_tokens,\n",
        "            chord_tokens=chord_tokens,\n",
        "            melody_padding_mask=melody_mask,\n",
        "            chord_padding_mask=chord_mask\n",
        "        )\n",
        "        \n",
        "        # Calculate loss\n",
        "        loss = loss_fn(melody_embeds, chord_embeds)\n",
        "        \n",
        "        # Check for NaN loss\n",
        "        if torch.isnan(loss):\n",
        "            print(f\"\\nNaN loss detected! Skipping batch.\")\n",
        "            continue\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update progress bar\n",
        "        total_loss += loss.item()\n",
        "        pbar.set_postfix({'loss': loss.item()})\n",
        "        \n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def validate(model, val_loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_ranks = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc='Validating'):\n",
        "            # Move batch to device\n",
        "            melody_tokens = batch['melody_tokens'].to(device)\n",
        "            chord_tokens = batch['chord_tokens'].to(device)\n",
        "            \n",
        "            # Create padding masks\n",
        "            melody_mask = (melody_tokens == model.pad_token_id)\n",
        "            chord_mask = (chord_tokens == model.pad_token_id)\n",
        "            \n",
        "            # Forward pass\n",
        "            melody_embeds, chord_embeds = model(\n",
        "                melody_tokens=melody_tokens,\n",
        "                chord_tokens=chord_tokens,\n",
        "                melody_padding_mask=melody_mask,\n",
        "                chord_padding_mask=chord_mask\n",
        "            )\n",
        "            \n",
        "            # Calculate loss\n",
        "            loss = loss_fn(melody_embeds, chord_embeds)\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "            # Calculate Top-1 Accuracy\n",
        "            logits = torch.matmul(\n",
        "                F.normalize(melody_embeds, p=2, dim=1),\n",
        "                F.normalize(chord_embeds, p=2, dim=1).T\n",
        "            )\n",
        "            sorted_indices = torch.argsort(logits, descending=True, dim=1)\n",
        "            labels = torch.arange(len(logits), device=logits.device)\n",
        "            ranks = (sorted_indices == labels[:, None]).nonzero(as_tuple=True)[1] + 1\n",
        "            all_ranks.extend(ranks.cpu().numpy())\n",
        "    \n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    top1_accuracy = np.mean(np.array(all_ranks) == 1) * 100\n",
        "    \n",
        "    return avg_loss, top1_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "best_val_loss = float('inf')\n",
        "global_step = 0\n",
        "\n",
        "try:\n",
        "    for epoch in range(config['epochs']):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{config['epochs']}\")\n",
        "        \n",
        "        # Clear GPU memory before each epoch\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            print(f\"GPU memory at start of epoch: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "        \n",
        "        # Training Step\n",
        "        train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device)\n",
        "        \n",
        "        # Validation Step\n",
        "        val_loss, top1_accuracy = validate(model, val_loader, loss_fn, device)\n",
        "        \n",
        "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Valid Loss: {val_loss:.4f}, Top-1 Accuracy: {top1_accuracy:.2f}%\")\n",
        "        wandb.log({\n",
        "            'train/epoch_loss': train_loss,\n",
        "            'valid/epoch_loss': val_loss,\n",
        "            'valid/top1_accuracy': top1_accuracy,\n",
        "            'epoch': epoch + 1\n",
        "        }, step=global_step)\n",
        "        \n",
        "        # Save checkpoint if validation loss improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            \n",
        "            # Save checkpoint locally\n",
        "            checkpoint_path = Path(\"checkpoints\") / f\"contrastive_reward_epoch_{epoch+1}.pth\"\n",
        "            checkpoint_path.parent.mkdir(exist_ok=True)\n",
        "            \n",
        "            checkpoint = {\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'top1_accuracy': top1_accuracy,\n",
        "                'config': config,\n",
        "            }\n",
        "            \n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "            \n",
        "            # Log checkpoint as wandb artifact\n",
        "            artifact = wandb.Artifact(\n",
        "                name=f\"contrastive_reward_model_{wandb.run.id}\",\n",
        "                type=\"model\",\n",
        "                description=f\"Contrastive Reward Model checkpoint from epoch {epoch+1}\"\n",
        "            )\n",
        "            artifact.add_file(str(checkpoint_path))\n",
        "            wandb.log_artifact(artifact)\n",
        "            \n",
        "            # Also save tokenizer info as artifact\n",
        "            tokenizer_artifact = wandb.Artifact(\n",
        "                name=f\"tokenizer_info_{wandb.run.id}\",\n",
        "                type=\"tokenizer\",\n",
        "                description=\"Tokenizer information used for training\"\n",
        "            )\n",
        "            tokenizer_path = Path(\"tokenizer_info.json\")\n",
        "            with open(tokenizer_path, 'w') as f:\n",
        "                json.dump(tokenizer_info, f)\n",
        "            tokenizer_artifact.add_file(str(tokenizer_path))\n",
        "            wandb.log_artifact(tokenizer_artifact)\n",
        "            \n",
        "            print(f\"\\nSaved checkpoint with validation loss: {val_loss:.4f}\")\n",
        "            \n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nTraining interrupted by user\")\n",
        "except torch.cuda.OutOfMemoryError:\n",
        "    print(\"\\nOut of GPU memory! Try reducing batch size or sequence length\")\n",
        "finally:\n",
        "    wandb.finish()\n",
        "    print(\"\\nTraining completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_best_checkpoint(model, checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    return checkpoint['val_loss'], checkpoint['top1_accuracy']\n",
        "\n",
        "# Example usage:\n",
        "# best_checkpoint_path = Path(wandb.run.dir) / 'best_checkpoint.pth'\n",
        "# best_val_loss, best_accuracy = load_best_checkpoint(model, best_checkpoint_path)\n",
        "# print(f\"Loaded checkpoint with validation loss: {best_val_loss:.4f} and accuracy: {best_accuracy:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
