{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/imabeastdrew/Martydepth.git\n",
        "%cd Martydepth\n",
        "\n",
        "# Install the package in development mode\n",
        "%pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip install torch wandb tqdm pyyaml transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from transformers import Adafactor\n",
        "from pathlib import Path\n",
        "import wandb\n",
        "import yaml\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add project root to Python path\n",
        "import sys\n",
        "sys.path.append('.')\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "# Import project modules\n",
        "from src.data.dataset import create_dataloader\n",
        "from src.models.offline_teacher import OfflineTeacherModel\n",
        "from src.models.offline_teacher_t5 import T5OfflineTeacherModel\n",
        "from src.config.tokenization_config import PAD_TOKEN, CHORD_TOKEN_START\n",
        "from src.training.utils.schedulers import get_warmup_schedule\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration - Set model type and checkpoint path here\n",
        "MODEL_TYPE = \"custom\"  # Change to \"t5\" to use T5OfflineTeacherModel\n",
        "CHECKPOINT_PATH = None  # Set to checkpoint path to resume training\n",
        "# Examples:\n",
        "# Local file: \"checkpoints/offline_teacher_epoch_5.pth\"\n",
        "# Wandb artifact: \"username/project/offline_teacher_model_runid:v0\"\n",
        "# Wandb artifact: \"offline_teacher_model_runid:latest\"\n",
        "\n",
        "# Load configuration based on model type\n",
        "if MODEL_TYPE == \"custom\":\n",
        "    config_path = 'src/training/configs/offline_teacher_base.yaml'\n",
        "elif MODEL_TYPE == \"t5\":\n",
        "    config_path = 'src/training/configs/offline_teacher_t5.yaml'\n",
        "else:\n",
        "    raise ValueError(f\"Unknown model type: {MODEL_TYPE}. Use 'custom' or 't5'\")\n",
        "\n",
        "print(f\"Loading config from: {config_path}\")\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Override model type if needed\n",
        "config['model_type'] = MODEL_TYPE\n",
        "\n",
        "# Training state variables (will be set from checkpoint if available)\n",
        "start_epoch = 0\n",
        "best_val_loss = float('inf')\n",
        "global_step = 0\n",
        "resume_from_checkpoint = CHECKPOINT_PATH is not None\n",
        "\n",
        "if resume_from_checkpoint:\n",
        "    print(f\"Will resume training from checkpoint: {CHECKPOINT_PATH}\")\n",
        "else:\n",
        "    print(\"Starting new training from scratch\")\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "print(f'ðŸŽµ Training {MODEL_TYPE.upper()} model')\n",
        "\n",
        "# Initialize wandb with model type in name\n",
        "model_type_for_name = config.get('model_type', 'custom')\n",
        "run_name = (\n",
        "    f\"offline_{model_type_for_name}_L{config['num_layers']}_H{config['num_heads']}\"\n",
        "    f\"_D{config['embed_dim']}_seq{config['max_sequence_length']}\"\n",
        "    f\"_bs{config['batch_size']}_lr{config['learning_rate']}\"\n",
        ")\n",
        "\n",
        "wandb.init(\n",
        "    project=config['wandb_project'],\n",
        "    name=run_name,\n",
        "    config=config,\n",
        "    job_type=\"offline_training\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataloaders\n",
        "train_loader, tokenizer_info = create_dataloader(\n",
        "    data_dir=Path(config['data_dir']),\n",
        "    split=\"train\",\n",
        "    batch_size=config['batch_size'],\n",
        "    num_workers=config['num_workers'],\n",
        "    sequence_length=config['max_sequence_length'],\n",
        "    mode='offline',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader, _ = create_dataloader(\n",
        "    data_dir=Path(config['data_dir']),\n",
        "    split=\"valid\",\n",
        "    batch_size=config['batch_size'],\n",
        "    num_workers=config['num_workers'],\n",
        "    sequence_length=config['max_sequence_length'],\n",
        "    mode='offline',\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize model, optimizer, criterion, and scheduler\n",
        "config['melody_vocab_size'] = tokenizer_info['melody_vocab_size']\n",
        "config['chord_vocab_size'] = tokenizer_info['chord_vocab_size']\n",
        "config['total_vocab_size'] = tokenizer_info['total_vocab_size']\n",
        "\n",
        "# --- Model Creation (Configurable) ---\n",
        "def create_model(model_type: str):\n",
        "    \"\"\"Create model based on configuration\"\"\"\n",
        "    if model_type == \"custom\":\n",
        "        return OfflineTeacherModel(\n",
        "            melody_vocab_size=config['melody_vocab_size'],\n",
        "            chord_vocab_size=config['chord_vocab_size'],\n",
        "            embed_dim=config['embed_dim'],\n",
        "            num_heads=config['num_heads'],\n",
        "            num_layers=config['num_layers'],\n",
        "            dropout=config['dropout'],\n",
        "            max_seq_length=config['max_sequence_length'],\n",
        "            pad_token_id=tokenizer_info.get('pad_token_id', PAD_TOKEN)\n",
        "        )\n",
        "    elif model_type == \"t5\":\n",
        "        return T5OfflineTeacherModel(\n",
        "            melody_vocab_size=config['melody_vocab_size'],\n",
        "            chord_vocab_size=config['chord_vocab_size'],\n",
        "            embed_dim=config['embed_dim'],\n",
        "            num_heads=config['num_heads'],\n",
        "            num_layers=config['num_layers'],\n",
        "            dropout=config['dropout'],\n",
        "            max_seq_length=config['max_sequence_length'],\n",
        "            pad_token_id=tokenizer_info.get('pad_token_id', PAD_TOKEN),\n",
        "            total_vocab_size=config['total_vocab_size']\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model_type: {model_type}. Use 'custom' or 't5'\")\n",
        "\n",
        "model_type = config.get('model_type', 'custom')  # Default to custom model\n",
        "model = create_model(model_type).to(device)\n",
        "\n",
        "print(f\"Using {model_type.upper()} model architecture\")\n",
        "print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "\n",
        "# Use AdamW optimizer for better stability and simpler hyperparameter tuning\n",
        "optimizer = AdamW(\n",
        "    model.parameters(), \n",
        "    lr=config['learning_rate'],\n",
        "    weight_decay=config.get('weight_decay', 0.01)\n",
        ")\n",
        "\n",
        "# Note: Cross-entropy loss will be calculated in the training function with proper vocab sizing\n",
        "pad_token_id = tokenizer_info.get('pad_token_id', PAD_TOKEN)\n",
        "\n",
        "# Initialize warmup scheduler\n",
        "scheduler = get_warmup_schedule(optimizer, num_warmup_steps=config['warmup_steps'])\n",
        "\n",
        "# Load checkpoint if specified\n",
        "if resume_from_checkpoint:\n",
        "    print(f\"Loading checkpoint from: {CHECKPOINT_PATH}\")\n",
        "    \n",
        "    # Helper function to load checkpoint from local path or wandb artifact\n",
        "    def load_checkpoint_file(checkpoint_path):\n",
        "        \"\"\"Load checkpoint from local file or wandb artifact\"\"\"\n",
        "        # Check if it's a wandb artifact reference (contains : and possibly /)\n",
        "        if ':' in checkpoint_path and not checkpoint_path.startswith('/') and not checkpoint_path.startswith('C:'):\n",
        "            print(f\"Downloading wandb artifact: {checkpoint_path}\")\n",
        "            try:\n",
        "                artifact = wandb.use_artifact(checkpoint_path, type=\"model\")\n",
        "                artifact_dir = artifact.download()\n",
        "                # Find the .pth file in the artifact directory\n",
        "                import os\n",
        "                checkpoint_files = [f for f in os.listdir(artifact_dir) if f.endswith('.pth')]\n",
        "                if not checkpoint_files:\n",
        "                    raise FileNotFoundError(f\"No .pth file found in artifact {checkpoint_path}\")\n",
        "                local_checkpoint_path = os.path.join(artifact_dir, checkpoint_files[0])\n",
        "                print(f\"Downloaded to: {local_checkpoint_path}\")\n",
        "                return torch.load(local_checkpoint_path, map_location=device)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to download wandb artifact: {e}\")\n",
        "                print(\"Make sure you're logged into wandb and have access to the artifact\")\n",
        "                raise\n",
        "        else:\n",
        "            # Local file path\n",
        "            print(f\"Loading local checkpoint: {checkpoint_path}\")\n",
        "            return torch.load(checkpoint_path, map_location=device)\n",
        "    \n",
        "    checkpoint = load_checkpoint_file(CHECKPOINT_PATH)\n",
        "    \n",
        "    # Load model state\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"Loaded model state from epoch {checkpoint['epoch']}\")\n",
        "    \n",
        "    # Load optimizer state\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    print(f\"Loaded optimizer state\")\n",
        "    \n",
        "    # Load scheduler state\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "    print(f\"Loaded scheduler state\")\n",
        "    \n",
        "    # Load training state\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    best_val_loss = checkpoint['val_loss']\n",
        "    global_step = checkpoint.get('global_step', start_epoch * len(train_loader))\n",
        "    \n",
        "    print(f\"Resuming training from epoch {start_epoch + 1}\")\n",
        "    print(f\"Best validation loss so far: {best_val_loss:.4f}\")\n",
        "    print(f\"Global step: {global_step}\")\n",
        "    \n",
        "    # Update run name to indicate resumed training\n",
        "    wandb.run.name = f\"{wandb.run.name}_resumed_epoch_{start_epoch}\"\n",
        "    \n",
        "    # Update config with checkpoint info\n",
        "    config['resumed_from_checkpoint'] = True\n",
        "    config['checkpoint_path'] = CHECKPOINT_PATH\n",
        "    config['resume_epoch'] = start_epoch\n",
        "\n",
        "# Enable gradient and parameter logging\n",
        "wandb.watch(model, log=\"all\", log_freq=config['log_every_n_steps'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, train_loader, optimizer, scheduler, device, global_step, epoch, model_type, config):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc='Training')\n",
        "    for batch_idx, batch in enumerate(pbar):\n",
        "        # Move batch to device\n",
        "        melody_tokens = batch['melody_tokens'].to(device)\n",
        "        chord_input = batch['chord_input'].to(device)\n",
        "        chord_target = batch['chord_target'].to(device)\n",
        "        \n",
        "        # Create padding masks (True means position should be masked)\n",
        "        melody_padding_mask = (melody_tokens == model.pad_token_id)  # [batch_size, src_len]\n",
        "        chord_padding_mask = (chord_input == model.pad_token_id)     # [batch_size, tgt_len]\n",
        "        \n",
        "        # Forward pass with proper masking (causal mask is handled internally)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(\n",
        "            melody_tokens=melody_tokens,\n",
        "            chord_tokens=chord_input,\n",
        "            melody_mask=melody_padding_mask,  # src_key_padding_mask\n",
        "            chord_mask=chord_padding_mask     # tgt_key_padding_mask\n",
        "        )\n",
        "        \n",
        "        # Use chord vocab size for both models to isolate architectural differences\n",
        "        vocab_size_for_loss = config['chord_vocab_size']\n",
        "        \n",
        "        # Extract chord-only logits for T5 model (which outputs full vocab)\n",
        "        if model_type == \"t5\":\n",
        "            # Chord tokens start at CHORD_TOKEN_START (179) in the full vocabulary\n",
        "            chord_logits = logits[:, :, CHORD_TOKEN_START:]  # [batch, seq, chord_vocab_size]\n",
        "            logits_for_loss = chord_logits\n",
        "            \n",
        "            # Adjust targets from full vocab space to chord-only space\n",
        "            # Original targets: [179, 180, ..., 4778] -> [0, 1, ..., 4599]\n",
        "            targets_for_loss = chord_target - CHORD_TOKEN_START\n",
        "            # Handle PAD tokens (they should remain as pad_token_id for ignore_index)\n",
        "            pad_mask = (chord_target == model.pad_token_id)\n",
        "            targets_for_loss[pad_mask] = model.pad_token_id\n",
        "        else:  # custom model already outputs chord-only\n",
        "            logits_for_loss = logits\n",
        "            targets_for_loss = chord_target  # Already in chord space\n",
        "            \n",
        "        # Calculate loss\n",
        "        loss = nn.functional.cross_entropy(\n",
        "            logits_for_loss.reshape(-1, vocab_size_for_loss),\n",
        "            targets_for_loss.reshape(-1),\n",
        "            ignore_index=model.pad_token_id\n",
        "        )\n",
        "        \n",
        "        # Check for NaN loss\n",
        "        if torch.isnan(loss):\n",
        "            print(f\"\\nNaN loss detected! Skipping batch.\")\n",
        "            if epoch < 3:  # Early epochs\n",
        "                print(\"NaN in early epoch - may need to reduce learning rate or increase warmup steps\")\n",
        "            continue\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip_val'])\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate each batch\n",
        "        \n",
        "        # Get current learning rate\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        \n",
        "        # Log batch metrics\n",
        "        if batch_idx % config['log_every_n_steps'] == 0:\n",
        "            wandb.log({\n",
        "                'train/batch_loss': loss.item(),\n",
        "                'train/learning_rate': lr,\n",
        "                'train/batch': batch_idx,\n",
        "                'train/epoch': epoch,\n",
        "                'train/grad_norm': torch.nn.utils.clip_grad_norm_(model.parameters(), float('inf')).item()\n",
        "            }, step=global_step)\n",
        "        \n",
        "        global_step += 1\n",
        "        \n",
        "        # Update progress bar\n",
        "        total_loss += loss.item()\n",
        "        pbar.set_postfix({'loss': loss.item(), 'lr': f\"{lr:.2e}\"})\n",
        "        \n",
        "    return total_loss / len(train_loader), global_step\n",
        "\n",
        "def validate(model, val_loader, device, model_type, config):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    nan_batches = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc='Validating'):\n",
        "            # Move batch to device\n",
        "            melody_tokens = batch['melody_tokens'].to(device)\n",
        "            chord_input = batch['chord_input'].to(device)\n",
        "            chord_target = batch['chord_target'].to(device)\n",
        "            \n",
        "            # Create padding masks (True means position should be masked)\n",
        "            melody_padding_mask = (melody_tokens == model.pad_token_id)  # [batch_size, src_len]\n",
        "            chord_padding_mask = (chord_input == model.pad_token_id)     # [batch_size, tgt_len]\n",
        "            \n",
        "            # Forward pass with proper masking (causal mask is handled internally)\n",
        "            logits = model(\n",
        "                melody_tokens=melody_tokens,\n",
        "                chord_tokens=chord_input,\n",
        "                melody_mask=melody_padding_mask,  # src_key_padding_mask\n",
        "                chord_mask=chord_padding_mask     # tgt_key_padding_mask\n",
        "            )\n",
        "            \n",
        "            # Use chord vocab size for both models to isolate architectural differences\n",
        "            vocab_size_for_loss = config['chord_vocab_size']\n",
        "            \n",
        "            # Extract chord-only logits for T5 model (which outputs full vocab)\n",
        "            if model_type == \"t5\":\n",
        "                # Chord tokens start at CHORD_TOKEN_START (179) in the full vocabulary\n",
        "                chord_logits = logits[:, :, CHORD_TOKEN_START:]  # [batch, seq, chord_vocab_size]\n",
        "                logits_for_loss = chord_logits\n",
        "                \n",
        "                # Adjust targets from full vocab space to chord-only space\n",
        "                # Original targets: [179, 180, ..., 4778] -> [0, 1, ..., 4599]\n",
        "                targets_for_loss = chord_target - CHORD_TOKEN_START\n",
        "                # Handle PAD tokens (they should remain as pad_token_id for ignore_index)\n",
        "                pad_mask = (chord_target == model.pad_token_id)\n",
        "                targets_for_loss[pad_mask] = model.pad_token_id\n",
        "            else:  # custom model already outputs chord-only\n",
        "                logits_for_loss = logits\n",
        "                targets_for_loss = chord_target  # Already in chord space\n",
        "                \n",
        "            # Calculate loss\n",
        "            loss = nn.functional.cross_entropy(\n",
        "                logits_for_loss.reshape(-1, vocab_size_for_loss),\n",
        "                targets_for_loss.reshape(-1),\n",
        "                ignore_index=model.pad_token_id\n",
        "            )\n",
        "            \n",
        "            # Check for NaN loss\n",
        "            if torch.isnan(loss):\n",
        "                nan_batches += 1\n",
        "                continue\n",
        "                \n",
        "            total_loss += loss.item()\n",
        "    \n",
        "    # Avoid division by zero if all batches were NaN\n",
        "    num_valid_batches = len(val_loader) - nan_batches\n",
        "    return total_loss / num_valid_batches if num_valid_batches > 0 else float('nan')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop (supports checkpoint resumption)\n",
        "print(f\"\\n--- Offline Training Info ---\")\n",
        "print(f\"  Model type: {model_type}\")\n",
        "print(f\"  Max epochs: {config['max_epochs']}\")\n",
        "print(f\"  Starting from epoch: {start_epoch + 1}\")\n",
        "print(f\"  Early stopping patience: {config.get('early_stopping_patience', 5)}\")\n",
        "print(f\"  Current best val loss: {best_val_loss:.4f}\")\n",
        "print(f\"  Resume from checkpoint: {resume_from_checkpoint}\")\n",
        "\n",
        "try:\n",
        "    for epoch in range(start_epoch, config['max_epochs']):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{config['max_epochs']}\")\n",
        "        \n",
        "        # Clear GPU memory before each epoch\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            print(f\"GPU memory at start of epoch: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "        \n",
        "        # Training Step\n",
        "        train_loss, global_step = train_epoch(model, train_loader, optimizer, scheduler, device, global_step, epoch, model_type, config)\n",
        "        \n",
        "        # Validation Step\n",
        "        val_loss = validate(model, val_loader, device, model_type, config)\n",
        "        \n",
        "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Valid Loss: {val_loss:.4f}\")\n",
        "        wandb.log({\n",
        "            'train/epoch_loss': train_loss,\n",
        "            'valid/epoch_loss': val_loss,\n",
        "            'epoch': epoch + 1,\n",
        "            'train/epoch': epoch + 1\n",
        "        }, step=global_step)\n",
        "        \n",
        "        # Save checkpoint if validation loss improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            \n",
        "            # Save checkpoint locally\n",
        "            checkpoint_path = Path(\"checkpoints\") / f\"offline_teacher_epoch_{epoch+1}.pth\"\n",
        "            checkpoint_path.parent.mkdir(exist_ok=True)\n",
        "            \n",
        "            checkpoint = {\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'config': config,\n",
        "                'global_step': global_step,\n",
        "                'best_val_loss': best_val_loss,\n",
        "            }\n",
        "            \n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "            \n",
        "            # Log checkpoint as wandb artifact\n",
        "            artifact = wandb.Artifact(\n",
        "                name=f\"offline_teacher_model_{wandb.run.id}\",\n",
        "                type=\"model\",\n",
        "                description=f\"Offline Teacher Model checkpoint from epoch {epoch+1}\"\n",
        "            )\n",
        "            artifact.add_file(str(checkpoint_path))\n",
        "            wandb.log_artifact(artifact)\n",
        "            \n",
        "            # Also save tokenizer info as artifact\n",
        "            tokenizer_artifact = wandb.Artifact(\n",
        "                name=f\"tokenizer_info_{wandb.run.id}\",\n",
        "                type=\"tokenizer\",\n",
        "                description=\"Tokenizer information used for training\"\n",
        "            )\n",
        "            tokenizer_path = Path(\"tokenizer_info.json\")\n",
        "            with open(tokenizer_path, 'w') as f:\n",
        "                json.dump(tokenizer_info, f)\n",
        "            tokenizer_artifact.add_file(str(tokenizer_path))\n",
        "            wandb.log_artifact(tokenizer_artifact)\n",
        "            \n",
        "            print(f\"\\nSaved checkpoint with validation loss: {val_loss:.4f}\")\n",
        "            \n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nTraining interrupted by user\")\n",
        "except torch.cuda.OutOfMemoryError:\n",
        "    print(\"\\nOut of GPU memory! Try reducing batch size or sequence length\")\n",
        "finally:\n",
        "    wandb.finish()\n",
        "    print(\"\\nTraining completed\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
