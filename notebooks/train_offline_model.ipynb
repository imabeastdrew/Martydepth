{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "!git clone -b <midi-tokenization> --single-branch https://github.com/imabeastdrew/Martydepth.git\n",
        "%cd Martydepth\n",
        "\n",
        "# Install the package in development mode\n",
        "%pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip install torch wandb tqdm pyyaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from pathlib import Path\n",
        "import wandb\n",
        "import yaml\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add project root to Python path\n",
        "import sys\n",
        "sys.path.append('.')\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "# Import project modules\n",
        "from src.data.dataset import create_dataloader\n",
        "from src.models.offline_teacher import OfflineTeacherModel\n",
        "from src.config.tokenization_config import PAD_TOKEN\n",
        "from src.training.utils.schedulers import get_warmup_schedule\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load configuration\n",
        "print(os.getcwd())\n",
        "config_path = 'src/training/configs/offline_teacher_base.yaml'\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Initialize wandb\n",
        "run_name = f\"offline_L{config['num_layers']}_H{config['num_heads']}_D{config['embed_dim']}_seq{config['max_sequence_length']}_bs{config['batch_size']}_lr{config['learning_rate']}\"\n",
        "\n",
        "wandb.init(\n",
        "    project=config['wandb_project'],\n",
        "    name=run_name,\n",
        "    config=config,\n",
        "    job_type=\"offline_training\"\n",
        ")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Create dataloaders\n",
        "train_loader, tokenizer_info = create_dataloader(\n",
        "    data_dir=Path(config['data_dir']),\n",
        "    split=\"train\",\n",
        "    batch_size=config['batch_size'],\n",
        "    num_workers=config['num_workers'],\n",
        "    sequence_length=config['max_sequence_length'],\n",
        "    mode='offline',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader, _ = create_dataloader(\n",
        "    data_dir=Path(config['data_dir']),\n",
        "    split=\"valid\",\n",
        "    batch_size=config['batch_size'],\n",
        "    num_workers=config['num_workers'],\n",
        "    sequence_length=config['max_sequence_length'],\n",
        "    mode='offline',\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize model, optimizer, criterion, and scheduler\n",
        "model = OfflineTeacherModel(\n",
        "    melody_vocab_size=tokenizer_info['melody_vocab_size'],\n",
        "    chord_vocab_size=tokenizer_info['chord_vocab_size'],\n",
        "    embed_dim=config['embed_dim'],\n",
        "    num_heads=config['num_heads'],\n",
        "    num_layers=config['num_layers'],\n",
        "    dropout=config['dropout'],\n",
        "    max_seq_length=config['max_sequence_length'],\n",
        "    pad_token_id=PAD_TOKEN\n",
        ").to(device)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=config['learning_rate'])\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
        "\n",
        "# Initialize warmup scheduler\n",
        "scheduler = get_warmup_schedule(optimizer, num_warmup_steps=config['warmup_steps'])\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc='Training')\n",
        "    for batch in pbar:\n",
        "        # Move batch to device\n",
        "        melody_tokens = batch['melody_tokens'].to(device)\n",
        "        chord_input = batch['chord_input'].to(device)\n",
        "        chord_target = batch['chord_target'].to(device)\n",
        "        \n",
        "        # Create padding masks (True means position should be masked)\n",
        "        melody_mask = (melody_tokens == model.pad_token_id)\n",
        "        chord_mask = (chord_input == model.pad_token_id)\n",
        "        \n",
        "        # Convert masks to float and invert (1 = keep, 0 = mask)\n",
        "        melody_mask = melody_mask.to(dtype=torch.float32)\n",
        "        melody_mask = melody_mask * -1e9  # Convert True to -inf for masking\n",
        "        \n",
        "        chord_mask = chord_mask.to(dtype=torch.float32)\n",
        "        chord_mask = chord_mask * -1e9  # Convert True to -inf for masking\n",
        "        \n",
        "        # Forward pass (causal mask is created internally)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(\n",
        "            melody_tokens=melody_tokens,\n",
        "            chord_tokens=chord_input,\n",
        "            melody_mask=melody_mask,\n",
        "            chord_mask=chord_mask\n",
        "        )\n",
        "        \n",
        "        # Calculate loss\n",
        "        loss = criterion(logits.view(-1, logits.size(-1)), chord_target.view(-1))\n",
        "        \n",
        "        # Check for NaN loss\n",
        "        if torch.isnan(loss):\n",
        "            print(f\"\\nNaN loss detected! Skipping batch.\")\n",
        "            if epoch < 3:  # Early epochs\n",
        "                print(\"NaN in early epoch - may need to reduce learning rate or increase warmup steps\")\n",
        "            continue\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), config['gradient_clip_val'])\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate each batch\n",
        "        \n",
        "        # Get current learning rate\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        \n",
        "        # Update progress bar\n",
        "        total_loss += loss.item()\n",
        "        pbar.set_postfix({'loss': loss.item(), 'lr': f\"{lr:.2e}\"})\n",
        "        \n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    nan_batches = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc='Validating'):\n",
        "            # Move batch to device\n",
        "            melody_tokens = batch['melody_tokens'].to(device)\n",
        "            chord_input = batch['chord_input'].to(device)\n",
        "            chord_target = batch['chord_target'].to(device)\n",
        "            \n",
        "            # Create padding masks (True means position should be masked)\n",
        "            melody_mask = (melody_tokens == model.pad_token_id)\n",
        "            chord_mask = (chord_input == model.pad_token_id)\n",
        "            \n",
        "            # Convert masks to float and invert (1 = keep, 0 = mask)\n",
        "            melody_mask = melody_mask.to(dtype=torch.float32)\n",
        "            melody_mask = melody_mask * -1e9  # Convert True to -inf for masking\n",
        "            \n",
        "            chord_mask = chord_mask.to(dtype=torch.float32)\n",
        "            chord_mask = chord_mask * -1e9  # Convert True to -inf for masking\n",
        "            \n",
        "            # Forward pass (causal mask is created internally)\n",
        "            logits = model(\n",
        "                melody_tokens=melody_tokens,\n",
        "                chord_tokens=chord_input,\n",
        "                melody_mask=melody_mask,\n",
        "                chord_mask=chord_mask\n",
        "            )\n",
        "            \n",
        "            # Calculate loss\n",
        "            loss = criterion(logits.view(-1, logits.size(-1)), chord_target.view(-1))\n",
        "            \n",
        "            # Check for NaN loss\n",
        "            if torch.isnan(loss):\n",
        "                nan_batches += 1\n",
        "                continue\n",
        "                \n",
        "            total_loss += loss.item()\n",
        "    \n",
        "    # Avoid division by zero if all batches were NaN\n",
        "    num_valid_batches = len(val_loader) - nan_batches\n",
        "    return total_loss / num_valid_batches if num_valid_batches > 0 else float('nan')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "best_val_loss = float('inf')\n",
        "global_step = 0\n",
        "\n",
        "try:\n",
        "    for epoch in range(config['max_epochs']):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{config['max_epochs']}\")\n",
        "        \n",
        "        # Clear GPU memory before each epoch\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            print(f\"GPU memory at start of epoch: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "        \n",
        "        # Training\n",
        "        train_loss = train_epoch(model, train_loader, criterion, optimizer, scheduler, device)\n",
        "        \n",
        "        # Validation\n",
        "        val_loss = validate(model, val_loader, criterion, device)\n",
        "        \n",
        "        # Log metrics\n",
        "        wandb.log({\n",
        "            'train/loss': train_loss,\n",
        "            'valid/loss': val_loss,\n",
        "            'learning_rate': optimizer.param_groups[0]['lr'],\n",
        "            'epoch': epoch + 1,\n",
        "            'gpu_memory_usage': torch.cuda.memory_allocated() / 1e9 if torch.cuda.is_available() else 0\n",
        "        })\n",
        "        \n",
        "        # Save checkpoint if validation loss improved\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            checkpoint_path = Path(wandb.run.dir) / f\"offline_teacher_epoch_{epoch+1}.pth\"\n",
        "            \n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'config': config,\n",
        "            }, checkpoint_path)\n",
        "            \n",
        "            wandb.save(str(checkpoint_path))\n",
        "            print(f\"\\nSaved checkpoint with validation loss: {val_loss:.4f}\")\n",
        "            \n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nTraining interrupted by user\")\n",
        "except torch.cuda.OutOfMemoryError:\n",
        "    print(\"\\nOut of GPU memory! Try reducing batch size or sequence length\")\n",
        "finally:\n",
        "    wandb.finish()\n",
        "    print(\"\\nTraining completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_best_checkpoint(model, checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    return checkpoint['val_loss']\n",
        "\n",
        "# Example usage:\n",
        "# best_checkpoint_path = Path(wandb.run.dir) / 'best_checkpoint.pth'\n",
        "# best_val_loss = load_best_checkpoint(model, best_checkpoint_path)\n",
        "# print(f\"Loaded checkpoint with validation loss: {best_val_loss:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
