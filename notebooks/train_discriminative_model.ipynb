{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "!git clone -b <midi-tokenization> --single-branch https://github.com/imabeastdrew/Martydepth.git\n",
        "%cd Martydepth\n",
        "\n",
        "# Install the package in development mode\n",
        "%pip install -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip install torch wandb tqdm pyyaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from pathlib import Path\n",
        "import wandb\n",
        "import yaml\n",
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add project root to Python path\n",
        "import sys\n",
        "sys.path.append('.')\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "# Import project modules\n",
        "from src.data.dataset import create_dataloader\n",
        "from src.models.discriminative_reward_model import DiscriminativeRewardModel\n",
        "from src.config.tokenization_config import PAD_TOKEN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load configuration\n",
        "print(os.getcwd())\n",
        "config_path = 'src/training/configs/discriminator_reward_base.yaml'\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Adjust sequence length to account for interleaving\n",
        "config['max_seq_length'] = config['max_seq_length'] // 2\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Initialize wandb\n",
        "run_name = f\"discriminator_L{config['num_layers']}_H{config['num_heads']}_D{config['embed_dim']}_seq{config['max_seq_length']*2}_bs{config['batch_size']}_lr{config['learning_rate']}\"\n",
        "\n",
        "wandb.init(\n",
        "    project=config['wandb_project'],\n",
        "    name=run_name,\n",
        "    config=config,\n",
        "    job_type=\"discriminator_training\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataloaders\n",
        "train_loader, tokenizer_info = create_dataloader(\n",
        "    data_dir=Path(config['data_dir']),\n",
        "    split=\"train\",\n",
        "    batch_size=config['batch_size'],\n",
        "    num_workers=config['num_workers'],\n",
        "    sequence_length=config['max_seq_length'],\n",
        "    mode='discriminator',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader, _ = create_dataloader(\n",
        "    data_dir=Path(config['data_dir']),\n",
        "    split=\"valid\",\n",
        "    batch_size=config['batch_size'],\n",
        "    num_workers=config['num_workers'],\n",
        "    sequence_length=config['max_seq_length'],\n",
        "    mode='discriminator',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "config['vocab_size'] = tokenizer_info['total_vocab_size']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize model, optimizer, and criterion\n",
        "model = DiscriminativeRewardModel(\n",
        "    vocab_size=config['vocab_size'],\n",
        "    embed_dim=config['embed_dim'],\n",
        "    num_heads=config['num_heads'],\n",
        "    num_layers=config['num_layers'],\n",
        "    dropout=config['dropout'],\n",
        "    max_seq_length=config['max_seq_length'] * 2,  # Account for interleaved sequences\n",
        "    pad_token_id=tokenizer_info.get('pad_token_id', PAD_TOKEN)\n",
        ").to(device)\n",
        "\n",
        "# Enable gradient and parameter monitoring\n",
        "wandb.watch(model, log='all', log_freq=100)\n",
        "print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters.\")\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=config['learning_rate'])\n",
        "loss_fn = nn.BCELoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_negative_samples(interleaved_tokens: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Creates negative samples by shuffling chord progressions within a batch.\n",
        "    \n",
        "    Args:\n",
        "        interleaved_tokens (torch.Tensor): A batch of real, interleaved sequences \n",
        "                                           [batch_size, seq_length] where tokens are\n",
        "                                           arranged as [c, m, c, m, ...].\n",
        "    \n",
        "    Returns:\n",
        "        torch.Tensor: A batch of fake sequences where melodies are paired with\n",
        "                      chords from other sequences in the batch.\n",
        "    \"\"\"\n",
        "    batch_size, seq_length = interleaved_tokens.shape\n",
        "    \n",
        "    # De-interleave into melody and chord tracks\n",
        "    melody_tokens = interleaved_tokens[:, 1::2]\n",
        "    chord_tokens = interleaved_tokens[:, 0::2]\n",
        "    \n",
        "    # Shuffle chord tokens across the batch dimension\n",
        "    # This creates the negative pairs\n",
        "    shuffled_indices = torch.randperm(batch_size)\n",
        "    shuffled_chord_tokens = chord_tokens[shuffled_indices]\n",
        "    \n",
        "    # Re-interleave to create the fake sequences\n",
        "    fake_interleaved = torch.empty_like(interleaved_tokens)\n",
        "    fake_interleaved[:, 1::2] = melody_tokens\n",
        "    fake_interleaved[:, 0::2] = shuffled_chord_tokens\n",
        "    \n",
        "    return fake_interleaved\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "best_val_loss = float('inf')\n",
        "global_step = 0\n",
        "\n",
        "try:\n",
        "    for epoch in range(config['epochs']):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{config['epochs']}\")\n",
        "        \n",
        "        # Clear GPU memory before each epoch\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            print(f\"GPU memory at start of epoch: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "        \n",
        "        # Training Step\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        \n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['epochs']} [Training]\")\n",
        "        for batch in pbar:\n",
        "            real_sequences = batch['interleaved_tokens'].to(device)\n",
        "            # Create negative samples by shuffling chords within the batch\n",
        "            fake_sequences = create_negative_samples(real_sequences)\n",
        "            \n",
        "            # Combine real and fake sequences for a single batch\n",
        "            # Shape: (2 * batch_size, seq_len)\n",
        "            combined_sequences = torch.cat([real_sequences, fake_sequences], dim=0)\n",
        "\n",
        "            # Generate padding mask for the combined batch\n",
        "            padding_mask = (combined_sequences == model.pad_token_id)\n",
        "            \n",
        "            # Create labels: 1 for real, 0 for fake\n",
        "            real_labels = torch.ones(real_sequences.size(0), 1, device=device)\n",
        "            fake_labels = torch.zeros(fake_sequences.size(0), 1, device=device)\n",
        "            combined_labels = torch.cat([real_labels, fake_labels], dim=0)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            predictions = model(combined_sequences, padding_mask=padding_mask)\n",
        "            \n",
        "            # Apply sigmoid since the model outputs logits\n",
        "            predictions = torch.sigmoid(predictions)\n",
        "\n",
        "            loss = loss_fn(predictions, combined_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            lr = optimizer.param_groups[0]['lr']\n",
        "            total_train_loss += loss.item()\n",
        "            global_step += 1\n",
        "            pbar.set_postfix({'loss': loss.item(), 'lr': lr})\n",
        "            wandb.log({'train/step_loss': loss.item(), 'train/learning_rate': lr}, step=global_step)\n",
        "            \n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        \n",
        "        # Validation Loop\n",
        "        model.eval()\n",
        "        total_valid_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pbar_valid = tqdm(valid_loader, desc=\"Validating\")\n",
        "            for batch in pbar_valid:\n",
        "                real_sequences = batch['interleaved_tokens'].to(device)\n",
        "                # Create negative samples for validation\n",
        "                fake_sequences = create_negative_samples(real_sequences)\n",
        "\n",
        "                combined_sequences = torch.cat([real_sequences, fake_sequences], dim=0)\n",
        "                padding_mask = (combined_sequences == model.pad_token_id)\n",
        "\n",
        "                real_labels = torch.ones(real_sequences.size(0), 1, device=device)\n",
        "                fake_labels = torch.zeros(fake_sequences.size(0), 1, device=device)\n",
        "                combined_labels = torch.cat([real_labels, fake_labels], dim=0)\n",
        "                \n",
        "                predictions = model(combined_sequences, padding_mask=padding_mask)\n",
        "                predictions = torch.sigmoid(predictions)\n",
        "                loss = loss_fn(predictions, combined_labels)\n",
        "                total_valid_loss += loss.item()\n",
        "\n",
        "                predicted_labels = (predictions > 0.5).float()\n",
        "                correct_predictions += (predicted_labels == combined_labels).sum().item()\n",
        "                total_predictions += combined_labels.size(0)\n",
        "\n",
        "                pbar_valid.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        avg_valid_loss = total_valid_loss / len(valid_loader)\n",
        "        accuracy = correct_predictions / total_predictions\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Valid Loss: {avg_valid_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "        wandb.log({\n",
        "            'train/epoch_loss': avg_train_loss,\n",
        "            'valid/epoch_loss': avg_valid_loss,\n",
        "            'valid/accuracy': accuracy,\n",
        "            'epoch': epoch + 1\n",
        "        }, step=global_step)\n",
        "        \n",
        "        # Save checkpoint if validation loss improved\n",
        "        if avg_valid_loss < best_val_loss:\n",
        "            best_val_loss = avg_valid_loss\n",
        "            # Save checkpoint locally\n",
        "            checkpoint_path = Path(\"checkpoints\") / f\"discriminator_reward_epoch_{epoch+1}.pth\"\n",
        "            checkpoint_path.parent.mkdir(exist_ok=True)\n",
        "            \n",
        "            checkpoint = {\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': avg_train_loss,\n",
        "                'val_loss': avg_valid_loss,\n",
        "                'accuracy': accuracy,\n",
        "                'config': config,\n",
        "            }\n",
        "            \n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "            \n",
        "            # Log checkpoint as wandb artifact\n",
        "            artifact = wandb.Artifact(\n",
        "                name=f\"discriminator_reward_model_{wandb.run.id}\",\n",
        "                type=\"model\",\n",
        "                description=f\"Discriminative Reward Model checkpoint from epoch {epoch+1}\"\n",
        "            )\n",
        "            artifact.add_file(str(checkpoint_path))\n",
        "            wandb.log_artifact(artifact)\n",
        "            \n",
        "            # Also save tokenizer info as artifact\n",
        "            tokenizer_artifact = wandb.Artifact(\n",
        "                name=f\"tokenizer_info_{wandb.run.id}\",\n",
        "                type=\"tokenizer\",\n",
        "                description=\"Tokenizer information used for training\"\n",
        "            )\n",
        "            tokenizer_path = Path(\"tokenizer_info.json\")\n",
        "            with open(tokenizer_path, 'w') as f:\n",
        "                json.dump(tokenizer_info, f)\n",
        "            tokenizer_artifact.add_file(str(tokenizer_path))\n",
        "            wandb.log_artifact(tokenizer_artifact)\n",
        "            \n",
        "            print(f\"\\nSaved checkpoint with validation loss: {avg_valid_loss:.4f}\")\n",
        "            \n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nTraining interrupted by user\")\n",
        "except torch.cuda.OutOfMemoryError:\n",
        "    print(\"\\nOut of GPU memory! Try reducing batch size or sequence length\")\n",
        "finally:\n",
        "    wandb.finish()\n",
        "    print(\"\\nTraining completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_best_checkpoint(model, checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    return checkpoint['val_loss'], checkpoint['accuracy']\n",
        "\n",
        "# Example usage:\n",
        "# best_checkpoint_path = Path(wandb.run.dir) / 'best_checkpoint.pth'\n",
        "# best_val_loss, best_accuracy = load_best_checkpoint(model, best_checkpoint_path)\n",
        "# print(f\"Loaded checkpoint with validation loss: {best_val_loss:.4f} and accuracy: {best_accuracy:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
