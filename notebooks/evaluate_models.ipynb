{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/imabeastdrew/Martydepth.git\n",
        "%cd Martydepth\n",
        "\n",
        "# Install the package in development mode\n",
        "%pip install -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip install torch wandb tqdm pyyaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import wandb\n",
        "import json\n",
        "import numpy as np\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add project root to Python path\n",
        "sys.path.append('.')\n",
        "\n",
        "# Import project modules\n",
        "from src.data.dataset import create_dataloader\n",
        "from src.models.online_transformer import OnlineTransformer\n",
        "from src.models.offline_teacher import OfflineTeacherModel\n",
        "from src.evaluation.metrics import (\n",
        "    calculate_harmony_metrics,\n",
        "    calculate_emd_metrics,\n",
        ")\n",
        "from src.config.tokenization_config import (\n",
        "    SILENCE_TOKEN,\n",
        "    MELODY_ONSET_HOLD_START,\n",
        "    CHORD_TOKEN_START,\n",
        "    PAD_TOKEN,\n",
        ")\n",
        "from src.evaluation.evaluate_offline import generate_offline\n",
        "from src.evaluation.evaluate import generate_online\n",
        "\n",
        "def load_model_artifact(artifact_path: str) -> tuple[dict, dict]:\n",
        "    \"\"\"\n",
        "    Load a model artifact and its config from wandb.\n",
        "    \n",
        "    Args:\n",
        "        artifact_path: Full path to the artifact (e.g. 'marty1ai/martydepth/model_name:version')\n",
        "    \n",
        "    Returns:\n",
        "        tuple[dict, dict]: Model state dict and config\n",
        "    \"\"\"\n",
        "    api = wandb.Api()\n",
        "    artifact = api.artifact(artifact_path)\n",
        "    \n",
        "    # Download the artifact\n",
        "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "        artifact_dir = artifact.download(tmp_dir)\n",
        "        checkpoint_file = next(Path(artifact_dir).glob(\"*.pth\"))\n",
        "        checkpoint = torch.load(checkpoint_file, map_location='cpu')\n",
        "    \n",
        "    return checkpoint['model_state_dict'], checkpoint['config']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "config = {\n",
        "    'data_dir': 'data/interim',\n",
        "    'split': 'test',\n",
        "    'batch_size': 32,\n",
        "    'num_workers': 4,\n",
        "    'temperature': 1.0,\n",
        "    'top_k': 50,\n",
        "    # Model artifact paths\n",
        "    'online_model_artifact': 'marty1ai/martydepth/online_transformer_model_np0myk09:v7',\n",
        "    'offline_model_artifact': 'marty1ai/martydepth/offline_teacher_model_rv8se0ur:v9'\n",
        "}\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else\n",
        "                     \"mps\" if torch.backends.mps.is_available() else\n",
        "                     \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(\n",
        "    project=\"martydepth\",\n",
        "    name=\"model_evaluation\",\n",
        "    config=config,\n",
        "    job_type=\"evaluation\"\n",
        ")\n",
        "\n",
        "# Load model artifacts\n",
        "print(\"\\nLoading model artifacts...\")\n",
        "\n",
        "# Online model\n",
        "online_state_dict, online_config = load_model_artifact(config['online_model_artifact'])\n",
        "print(f\"Loaded online model from {config['online_model_artifact']}\")\n",
        "\n",
        "# Offline model\n",
        "offline_state_dict, offline_config = load_model_artifact(config['offline_model_artifact'])\n",
        "print(f\"Loaded offline model from {config['offline_model_artifact']}\")\n",
        "\n",
        "# Load tokenizer info from data directory\n",
        "tokenizer_info_path = Path(config['data_dir']) / \"train\" / \"tokenizer_info.json\"\n",
        "with open(tokenizer_info_path, 'r') as f:\n",
        "    tokenizer_info = json.load(f)\n",
        "print(\"Loaded tokenizer info from data directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate Online Model\n",
        "print(\"\\n=== Evaluating Online Model ===\")\n",
        "\n",
        "# Initialize model\n",
        "model = OnlineTransformer(\n",
        "    vocab_size=tokenizer_info['total_vocab_size'],\n",
        "    embed_dim=online_config['embed_dim'],\n",
        "    num_heads=online_config['num_heads'],\n",
        "    num_layers=online_config['num_layers'],\n",
        "    dropout=online_config['dropout'],\n",
        "    max_seq_length=online_config.get('max_seq_length', 512),\n",
        "    pad_token_id=PAD_TOKEN\n",
        ").to(device)\n",
        "\n",
        "# Load state dict\n",
        "model.load_state_dict(online_state_dict)\n",
        "model.eval()\n",
        "\n",
        "# Create dataloader\n",
        "max_seq_length = online_config.get('max_seq_length') or online_config.get('max_sequence_length') or 512\n",
        "dataloader, _ = create_dataloader(\n",
        "    data_dir=Path(config['data_dir']),\n",
        "    split=config['split'],\n",
        "    batch_size=config['batch_size'],\n",
        "    num_workers=config['num_workers'],\n",
        "    sequence_length=max_seq_length,\n",
        "    mode='online',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Generate sequences\n",
        "print(\"\\nGenerating sequences...\")\n",
        "generated_sequences, ground_truth_sequences = generate_online(\n",
        "    model=model,\n",
        "    dataloader=dataloader,\n",
        "    tokenizer_info=tokenizer_info,\n",
        "    device=device,\n",
        "    temperature=config['temperature'],\n",
        "    top_k=config['top_k']\n",
        ")\n",
        "\n",
        "# Calculate metrics\n",
        "print(\"\\nCalculating metrics...\")\n",
        "harmony_metrics = calculate_harmony_metrics(generated_sequences, tokenizer_info)\n",
        "emd_metrics = calculate_emd_metrics(generated_sequences, ground_truth_sequences, tokenizer_info)\n",
        "\n",
        "online_metrics = {**harmony_metrics, **emd_metrics}\n",
        "\n",
        "print(\"\\n=== Online Model Results ===\")\n",
        "for metric, value in online_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "    wandb.log({f\"online/{metric}\": value})\n",
        "    \n",
        "# Log the artifact version we evaluated\n",
        "wandb.log({\"online_model_artifact\": config['online_model_artifact']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate Offline Model\n",
        "print(\"\\n=== Evaluating Offline Model ===\")\n",
        "\n",
        "# Initialize model\n",
        "model = OfflineTeacherModel(\n",
        "    vocab_size=tokenizer_info['total_vocab_size'],\n",
        "    embed_dim=offline_config['embed_dim'],\n",
        "    num_heads=offline_config['num_heads'],\n",
        "    num_layers=offline_config['num_layers'],\n",
        "    dropout=offline_config['dropout'],\n",
        "    max_seq_length=offline_config.get('max_seq_length', 512),\n",
        "    pad_token_id=PAD_TOKEN\n",
        ").to(device)\n",
        "\n",
        "# Load state dict\n",
        "model.load_state_dict(offline_state_dict)\n",
        "model.eval()\n",
        "\n",
        "# Create dataloader\n",
        "max_seq_length = offline_config.get('max_seq_length') or offline_config.get('max_sequence_length') or 512\n",
        "dataloader, _ = create_dataloader(\n",
        "    data_dir=Path(config['data_dir']),\n",
        "    split=config['split'],\n",
        "    batch_size=config['batch_size'],\n",
        "    num_workers=config['num_workers'],\n",
        "    sequence_length=max_seq_length,\n",
        "    mode='offline',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Generate sequences\n",
        "print(\"\\nGenerating sequences...\")\n",
        "generated_sequences, ground_truth_sequences = generate_offline(\n",
        "    model=model,\n",
        "    dataloader=dataloader,\n",
        "    tokenizer_info=tokenizer_info,\n",
        "    device=device,\n",
        "    temperature=config['temperature'],\n",
        "    top_k=config['top_k']\n",
        ")\n",
        "\n",
        "# Calculate metrics\n",
        "print(\"\\nCalculating metrics...\")\n",
        "harmony_metrics = calculate_harmony_metrics(generated_sequences, tokenizer_info)\n",
        "emd_metrics = calculate_emd_metrics(generated_sequences, ground_truth_sequences, tokenizer_info)\n",
        "\n",
        "offline_metrics = {**harmony_metrics, **emd_metrics}\n",
        "\n",
        "print(\"\\n=== Offline Model Results ===\")\n",
        "for metric, value in offline_metrics.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "    wandb.log({f\"offline/{metric}\": value})\n",
        "    \n",
        "# Log the artifact version we evaluated\n",
        "wandb.log({\"offline_model_artifact\": config['offline_model_artifact']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare Results\n",
        "print(\"\\n=== Model Comparison ===\")\n",
        "print(f\"{'Metric':<30} {'Online':<10} {'Offline':<10} {'Difference':<10}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for metric in online_metrics.keys():\n",
        "    online_value = online_metrics[metric]\n",
        "    offline_value = offline_metrics[metric]\n",
        "    diff = online_value - offline_value\n",
        "    print(f\"{metric:<30} {online_value:>10.4f} {offline_value:>10.4f} {diff:>10.4f}\")\n",
        "    wandb.log({\n",
        "        f\"comparison/{metric}_diff\": diff,\n",
        "        f\"comparison/{metric}_ratio\": online_value / offline_value if offline_value != 0 else 0\n",
        "    })\n",
        "\n",
        "# Finish wandb run\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
